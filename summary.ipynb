{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: license expired\n",
      "\n",
      "    the package numpy 1.10.2 was published on 2015-12-14,\n",
      "    however the mkl license expiration date is 2015-08-05.\n",
      "    You may be able to run earlier versions of numpy using your\n",
      "    current license.  A new license can be purchased at: http://continuum.io\n",
      "    To revert to an earlier set of conda packages, use:\n",
      "    $ conda list --revisions\n",
      "    ...\n",
      "    $ conda install --revision <REVISION NUMBER>\n",
      "\n",
      "    \n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: license expired\n",
      "\n",
      "    the package numpy 1.10.2 was published on 2015-12-14,\n",
      "    however the mkl license expiration date is 2015-08-05.\n",
      "    You may be able to run earlier versions of numpy using your\n",
      "    current license.  A new license can be purchased at: http://continuum.io\n",
      "    To revert to an earlier set of conda packages, use:\n",
      "    $ conda list --revisions\n",
      "    ...\n",
      "    $ conda install --revision <REVISION NUMBER>\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "import statsmodels.api as sm\n",
    "% matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "base_dir = '/om/user/zqi/projects/slbeh/cogscigame/data_structured/concatenated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lm(X, y):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    clf = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('lm', linear_model.LinearRegression())\n",
    "    ])\n",
    "    clf.fit(X, y)\n",
    "    coef = clf.named_steps[\"lm\"].coef_\n",
    "    return coef\n",
    "\n",
    "def poly(X, y):\n",
    "    if len(X.shape) == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "    clf = Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=3)),\n",
    "        ('scale', StandardScaler()),\n",
    "        ('lm', linear_model.LinearRegression())\n",
    "    ])\n",
    "    clf.fit(X, y)\n",
    "    return clf.named_steps[\"lm\"].coef_\n",
    "    \n",
    "def group_familiarization_summary(path):\n",
    "    data = pd.read_csv(path)\n",
    "    pars = data.groupby('id')\n",
    "    summary_mat = np.zeros((len(pars), 6), dtype=object)\n",
    "    for idx, (name, group) in enumerate(pars):\n",
    "        summary_mat[idx, 0] = name\n",
    "        summary_mat[idx, 1] = lm(\n",
    "            group.trial_index.values.astype(float), \n",
    "            group.rt.values.astype(float)\n",
    "        )[0]\n",
    "        summary_mat[idx, 2] = group.rt.mean()\n",
    "        coefs = poly(\n",
    "            group.trial_index.values.astype(float),\n",
    "            group.rt.values.astype(float)\n",
    "                    )\n",
    "        summary_mat[idx, 3] = coefs[1]\n",
    "        summary_mat[idx, 4] = coefs[2]\n",
    "        summary_mat[idx, 5] = coefs[3]\n",
    "    cols = ['id','lm_coef_rt', 'mean_rt', 'poly1', 'poly2', 'poly3']\n",
    "    return pd.DataFrame(summary_mat, columns=cols)\n",
    "\n",
    "def group_fam_target_summary(path):\n",
    "    data = pd.read_csv(vslfamacc)\n",
    "    pars = data.groupby('id')\n",
    "    summary_mat = np.zeros((len(pars), 2), dtype=object)\n",
    "    for idx, (name, group) in enumerate(pars):\n",
    "        hit = 0\n",
    "        trials = len(group.stimulus)\n",
    "        for i in range(trials):\n",
    "            if group.targ.values[i] in group.stimulus.values[i]:\n",
    "                hit = hit + 1\n",
    "        summary_mat[idx, 0] = name\n",
    "        summary_mat[idx, 1] = hit/trials\n",
    "    return pd.DataFrame(summary_mat, columns=['id','fam_acc'])\n",
    "\n",
    "def group_test_summary(path):\n",
    "    data = pd.read_csv(path)\n",
    "    pars = data.groupby('id')\n",
    "    summary_mat = np.zeros((len(pars), 2), dtype=object)\n",
    "    for idx, (name, group) in enumerate(pars):\n",
    "        summary_mat[idx, 0] = name\n",
    "        summary_mat[idx, 1] = (group.par_answer == group.expected_answer).mean()\n",
    "    return pd.DataFrame(summary_mat, columns=['id','acc'])\n",
    "\n",
    "def combine_summary(rt, acc, famacc):\n",
    "    out = rt.set_index('id').loc[acc['id']]\n",
    "    out['id_rt'] = out.index.values\n",
    "    out.index = [idx for idx in range(out.shape[0])]\n",
    "    out['id_acc'] = acc['id'].values\n",
    "    out['id_famacc'] = famacc['id'].values\n",
    "    out['acc'] = acc['acc'].values\n",
    "    out['fam_acc'] = famacc['fam_acc'].values\n",
    "    if not np.all(out.id_acc == out.id_rt):\n",
    "        print(\"IDs DO NOT MATCH\")\n",
    "    if not np.all(out.id_famacc == out.id_rt):\n",
    "        print(\"IDs DO NOT MATCH\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vslfamphase=os.path.join(base_dir, 'retest_vsl_tbt_famphase.csv')\n",
    "vsltest=os.path.join(base_dir, 'retest_vsl_tbt_testphase.csv')\n",
    "vslfamacc=os.path.join(base_dir, 'retest_vsl_tbt_famphase_falsePos.csv')\n",
    "tslfamphase=os.path.join(base_dir, 'retest_tsl_tbt_famphase.csv')\n",
    "tsltest=os.path.join(base_dir, 'retest_tsl_tbt_testphase.csv')\n",
    "tslfamacc=os.path.join(base_dir, 'retest_tsl_tbt_famphase_falsePos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id    fam_acc\n",
      "0   3064          1\n",
      "1   3067   0.958333\n",
      "2   3068   0.666667\n",
      "3   3130          1\n",
      "4   3144   0.857143\n",
      "5   3161          1\n",
      "6   3181   0.916667\n",
      "7   3182   0.821429\n",
      "8   3213          1\n",
      "9   3219   0.913043\n",
      "10  3223          1\n",
      "11  3236  0.0989011\n",
      "12  3237   0.923077\n",
      "13  3266       0.96\n",
      "14  3267   0.923077\n",
      "15  3268          1\n",
      "16  3311  0.0909091\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(vslfamacc)\n",
    "pars = data.groupby('id')\n",
    "summary_mat = np.zeros((len(pars), 2), dtype=object)\n",
    "for idx, (name, group) in enumerate(pars):\n",
    "    hit = 0\n",
    "    trials = len(group.stimulus)\n",
    "    for i in range(trials):\n",
    "        if group.targ.values[i] in group.stimulus.values[i]:\n",
    "            hit = hit + 1\n",
    "    summary_mat[idx, 0] = name\n",
    "    summary_mat[idx, 1] = hit/trials\n",
    "print pd.DataFrame(summary_mat, columns=['id','fam_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for g in [\n",
    "    (vslfamphase, vsltest, vslfamacc),\n",
    "    (tslfamphase, tsltest, tslfamacc)\n",
    "]:\n",
    "    rt = group_familiarization_summary(g[0])\n",
    "    acc = group_test_summary(g[1])\n",
    "    famacc = group_fam_target_summary(g[2])\n",
    "    combine_summary(rt, acc, famacc).to_csv(os.path.join(base_dir,'summary/summary_retest_{}.csv'.format(g[0][73:76])))\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
